{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"./mgtoolkit\")\n",
    "sys.path.append(\"./mgutils\")\n",
    "from mgtoolkit import *\n",
    "import json\n",
    "import os\n",
    "from mgutils.nodes import *\n",
    "from mgutils.utils import *\n",
    "from collections import *\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination_pairs(arr):\n",
    "    n = len(arr)\n",
    "    combinations = []\n",
    "    result = []\n",
    "    for size in range(1, n + 1):\n",
    "        for i in range(n - size + 1):\n",
    "            combinations.append(arr[i:i+size])\n",
    "    for i in range(len(combinations)):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                result.append([combinations[i], [arr[j]]])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "7\n",
      "8\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "path_to_json = './attackflows'\n",
    "json_files = [pos_json for pos_json in os.listdir(\n",
    "    path_to_json) if pos_json.endswith('.json')]\n",
    "ignore_files = [\"JP Morgan Breach.json\",\n",
    "                \"FIN13 Case 2.json\", \"Gootloader.json\", \"Target Breach.json\", \"Hancitor DLL.json\", \"NotPetya.json\", \"Ragnar Locker.json\"]\n",
    "big_files = [\"FIN13 Case 1.json\", \"Cobalt Kitty Campaign.json\", \"apt-chaining-vulnerabilities.json\", \"SolarWinds.json\", \"Conti Ransomware.json\", \"WhisperGate.json\", \"IcedID.json\", \"cleared-defense-contractor-networks.json\"]\n",
    "# # DEFINE NODE CLASS\n",
    "i = 0\n",
    "excel_path = 'mainMetagraph.xlsx'\n",
    "x = []\n",
    "y = []\n",
    "print(len(json_files))\n",
    "print(len(ignore_files))\n",
    "print(len(big_files))\n",
    "print(len(json_files)-len(ignore_files)-len(big_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muddy Water.json\n",
      "54\n",
      "[]\n",
      "Error:  Target Breach.json\n",
      "SWIFT Heist.json\n",
      "24\n",
      "[Send money to individual accounts, Send money to Philippines account] [T1070.004]\n",
      "[]\n",
      "[Send money to individual accounts, Send money to Philippines account]\n",
      "Tesla.json\n",
      "18\n",
      "solarwinds 2.json\n",
      "25\n",
      "Error:  apt-chaining-vulnerabilities.json\n",
      "Error:  network-infrastructure-devicesent.json\n",
      "Error:  JP Morgan Breach.json\n",
      "apt-compromise.json\n",
      "43\n",
      "[T1078, T1110.001, T1110.003] [T1569.002]\n",
      "[T1195.002, T1195.001:] [T1584]\n",
      "[T1057, T1518, T1083, T1518.001] [T1027, T1027.003, T1070.004]\n",
      "[T1078, T1110.001, T1110.003]\n",
      "[T1195.002, T1195.001:]\n",
      "[T1057, T1518, T1083, T1518.001]\n",
      "Sony Malware.json\n",
      "63\n",
      "[T1485, Dismounts, T1489] [T1132]\n",
      "[T1485, Dismounts, T1489]\n",
      "Equifax Breach.json\n",
      "40\n",
      "[T1590, T1589.001] [T1573]\n",
      "[T1140, T1560] [T1048.002]\n",
      "[T1590, T1589.001]\n",
      "[T1140, T1560]\n",
      "Conti CISA Alert.json\n",
      "36\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Error:  FIN13 Case 1.json\n",
      "Error:  Hancitor DLL.json\n",
      "Uber Breach.json\n",
      "30\n",
      "Error:  Gootloader.json\n",
      "CISA Iranian APT.json\n",
      "76\n",
      "Error:  SolarWinds.json\n",
      "Marriott Breach.json\n",
      "24\n",
      "[T1555, Remote Access Trojan] [T1590.004]\n",
      "[T1560, T1001] [TA0010]\n",
      "[T1555, Remote Access Trojan]\n",
      "[T1560, T1001]\n",
      "svr-cyber-actors.json\n",
      "20\n",
      "[T1595.002, T1190] [T1195.002]\n",
      "[T1595.002, T1190]\n",
      "triton-ics.json\n",
      "28\n",
      "[T0885, T0853] [T0857]\n",
      "[]\n",
      "[T0885, T0853]\n",
      "Error:  NotPetya.json\n",
      "Error:  mars information stealer malware.json\n",
      "mfa-printnightmare.json\n",
      "30\n",
      "Error:  Conti Ransomware.json\n",
      "Conti PWC.json\n",
      "20\n",
      "Error:  WhisperGate.json\n",
      "AgentTeslaUkraine.json\n",
      "11\n",
      "Tesla Kubernetes Breach.json\n",
      "18\n",
      "[T1610, T0884] [T1496]\n",
      "[T1610, T0884]\n",
      "Error:  FIN13 Case 2.json\n",
      "GoMet.json\n",
      "8\n",
      "Error:  Ragnar Locker.json\n",
      "Go Elephant.json\n",
      "10\n",
      "Mac Malware Steals Crypto.json\n",
      "35\n",
      "[TA0010] [T1105]\n",
      "[TA0010]\n",
      "Sunseed.json\n",
      "14\n",
      "Error:  cleared-defense-contractor-networks.json\n",
      "Error:  Cobalt Kitty Campaign.json\n",
      "Error:  IcedID.json\n",
      "havex-malware-ics.json\n",
      "32\n",
      "[T0862, T0817] [T0863]\n",
      "[T0862, T0817]\n",
      "matanbuchus.json\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(json_files)):\n",
    "    file = json_files[i]\n",
    "    if file in ignore_files or file in big_files or len(file) > 30:\n",
    "        print('Error: ', file)\n",
    "        continue\n",
    "    if file in big_files or len(file) > 30:\n",
    "        print('Big file: ', file)\n",
    "        continue\n",
    "    print(file)\n",
    "    f = open('attackflows/'+file)\n",
    "    data = json.load(f)\n",
    "    objects = data[\"objects\"]\n",
    "    \n",
    "    print(len(objects))\n",
    "    \n",
    "    # Create nodes from json file\n",
    "\n",
    "    nodeById, allNodes = convertAllToNodes(objects)\n",
    "\n",
    "    # Create list for metagraph and add \"attack-action\", \"attack-asset\" and \"STIX Common Properties\" node to the list\n",
    "    generating_set = set()\n",
    "    for node in allNodes[\"actions\"]:\n",
    "        generating_set.add(node)\n",
    "    # Create metagraph\n",
    "    mg = Metagraph(generating_set)\n",
    "\n",
    "    elementsSum = 0\n",
    "    for k, v in allNodes.items():\n",
    "        if k != 'operators':\n",
    "            elementsSum += len(v)\n",
    "\n",
    "    flow_dict = defaultdict(list)\n",
    "    \n",
    "    # set outNodes for each operator\n",
    "    for node in allNodes[\"operators\"]:\n",
    "        outnodes = []\n",
    "        for ref in node.effect_refs:\n",
    "            for outNode in generating_set:\n",
    "                if outNode.getId() == ref:\n",
    "                    outnodes.append(outNode)\n",
    "            node.setOutNodes(outnodes)\n",
    "            \n",
    "     # Generate edges for the metagraph\n",
    "    mg, flow_dict = createAttackEdge(mg, generating_set, nodeById, flow_dict)\n",
    "\n",
    "    mg, flow_dict = createOperatorEdge(mg, allNodes[\"operators\"], flow_dict)\n",
    "\n",
    "    for node in allNodes[\"operators\"]:\n",
    "        print(node.inNodes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muddy Water.json\n",
      "54\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(json_files)):\n",
    "    file = json_files[i]\n",
    "    if file in ignore_files or file in big_files or len(file) > 30:\n",
    "        print('Error: ', file)\n",
    "        continue\n",
    "    if file in big_files or len(file) > 30:\n",
    "        print('Big file: ', file)\n",
    "        continue\n",
    "    print(file)\n",
    "    f = open('attackflows/'+file)\n",
    "    data = json.load(f)\n",
    "    objects = data[\"objects\"]\n",
    "    \n",
    "    print(len(objects))\n",
    "\n",
    "    # Create nodes from json file\n",
    "\n",
    "    nodeById, allNodes = convertAllToNodes(objects)\n",
    "\n",
    "    # Create list for metagraph and add \"attack-action\", \"attack-asset\" and \"STIX Common Properties\" node to the list\n",
    "    generating_set = set()\n",
    "\n",
    "    for node in allNodes[\"actions\"]:\n",
    "        generating_set.add(node)\n",
    "    # Create metagraph\n",
    "    mg = Metagraph(generating_set)\n",
    "\n",
    "    elementsSum = 0\n",
    "    for k, v in allNodes.items():\n",
    "        if k != 'operators':\n",
    "            elementsSum += len(v)\n",
    "\n",
    "    flow_dict = defaultdict(list)\n",
    "    \n",
    "    # set outNodes for each operator\n",
    "    for node in allNodes[\"operators\"]:\n",
    "        outnodes = []\n",
    "        for ref in node.effect_refs:\n",
    "            for outNode in generating_set:\n",
    "                if outNode.getId() == ref:\n",
    "                    outnodes.append(outNode)\n",
    "            node.setOutNodes(outnodes)\n",
    "\n",
    "    # Generate edges for the metagraph\n",
    "    mg, flow_dict = createAttackEdge(mg, generating_set, nodeById, flow_dict)\n",
    "\n",
    "    mg, flow_dict = createOperatorEdge(mg, allNodes[\"operators\"], flow_dict)\n",
    "\n",
    "    for node in allNodes[\"operators\"]:\n",
    "        print(node.inNodes)\n",
    "\n",
    "    # from relationships\n",
    "    mg, flow_dict = createRelationshipEdge(\n",
    "        mg, allNodes[\"relationships\"], nodeById, flow_dict)\n",
    "\n",
    "    # metagraph adjacency matrix and incidence\n",
    "    A = mg.adjacency_matrix()\n",
    "    I = mg.incidence_matrix()\n",
    "\n",
    "    combination_pairs = get_combination_pairs(list(generating_set))\n",
    "\n",
    "    number_of_metapaths = 0\n",
    "    avg_edge_list = 0\n",
    "    avg_include_nodes = 0\n",
    "    metapaths_set = set()\n",
    "    longest_metapath = float('-inf')\n",
    "    shortest_metapath = float('inf')\n",
    "    freq_nodes = {}\n",
    "    for pair in combination_pairs:\n",
    "        if set(pair[0]) != set(pair[1]):\n",
    "            metapaths = mg.get_all_metapaths_from(set(pair[0]), set(pair[1]))\n",
    "            if metapaths != None and len(metapaths) > 0:\n",
    "                metapaths_set.update(metapaths)\n",
    "                for metapath in metapaths:\n",
    "                    number_of_metapaths += 1\n",
    "                    longest_metapath = max(longest_metapath, len(metapath.edge_list))\n",
    "                    shortest_metapath = min(shortest_metapath, len(metapath.edge_list))\n",
    "                    included_nodes = set()\n",
    "                    avg_edge_list += len(metapath.edge_list)\n",
    "                    for edge in metapath.edge_list:\n",
    "                        for tmp_node in edge.invertex.union(edge.outvertex):\n",
    "                            if tmp_node not in freq_nodes:\n",
    "                                freq_nodes[tmp_node] = 1\n",
    "                            else:\n",
    "                                freq_nodes[tmp_node]+=1\n",
    "                            included_nodes.add(tmp_node)\n",
    "                    avg_include_nodes += len(included_nodes)\n",
    "    sorted_tuples = sorted(freq_nodes.items(), key=lambda x: x[1], reverse=True)\n",
    "    number_of_metapaths = len(metapaths_set)\n",
    "    avg_include_nodes = avg_include_nodes//number_of_metapaths\n",
    "    avg_edge_list = avg_edge_list//number_of_metapaths\n",
    "    x.append(len(mg.edges))\n",
    "    y.append(sorted_tuples[0][1])\n",
    "    print('number of nodes:', len(generating_set))\n",
    "    print('number of edges:', len(mg.edges))\n",
    "    print('Number of metapaths:', number_of_metapaths)\n",
    "    print('Average number of include nodes:', avg_include_nodes)\n",
    "    print('Average path length:', avg_edge_list)\n",
    "    print('Highest degree nodes:', mg.get_most_degree_nodes())\n",
    "    print('Highest rank nodes:', mg.get_most_rank_nodes())\n",
    "    print(f'Attackflow {file[:-5]} has {len(generating_set)} nodes, {len(mg.edges)} edges, {number_of_metapaths} metapaths (longest: {longest_metapath}, shortest: {shortest_metapath}), the average paths length is {avg_edge_list}, the nodes with highest degree is {mg.get_most_degree_nodes()}, the nodes with highest rank is {mg.get_most_rank_nodes()}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(json_files)):\n",
    "    file = json_files[i]\n",
    "    if file in ignore_files or file in big_files or len(file) > 30:\n",
    "        print('Error: ', file)\n",
    "        continue\n",
    "    if file in big_files or len(file) > 30:\n",
    "        print('Big file: ', file)\n",
    "        continue\n",
    "    print(file)\n",
    "    f = open('attackflows/'+file)\n",
    "    data = json.load(f)\n",
    "    objects = data[\"objects\"]\n",
    "\n",
    "    # Create nodes from json file\n",
    "\n",
    "    nodeById, allNodes = convertAllToNodes(objects)\n",
    "\n",
    "    # Create list for metagraph and add \"attack-action\", \"attack-asset\" and \"STIX Common Properties\" node to the list\n",
    "    generating_set = set()\n",
    "\n",
    "    for node in allNodes[\"actions\"]:\n",
    "        generating_set.add(node)\n",
    "    # Create metagraph\n",
    "    mg = Metagraph(generating_set)\n",
    "\n",
    "    elementsSum = 0\n",
    "    for k, v in allNodes.items():\n",
    "        if k != 'operators':\n",
    "            elementsSum += len(v)\n",
    "\n",
    "    flow_dict = defaultdict(list)\n",
    "    \n",
    "    # set outNodes for each operator\n",
    "    for node in allNodes[\"operators\"]:\n",
    "        outnodes = []\n",
    "        for ref in node.effect_refs:\n",
    "            for outNode in generating_set:\n",
    "                if outNode.getId() == ref:\n",
    "                    outnodes.append(outNode)\n",
    "            node.setOutNodes(outnodes)\n",
    "\n",
    "    # Generate edges for the metagraph\n",
    "    mg, flow_dict = createAttackEdge(mg, generating_set, nodeById, flow_dict)\n",
    "\n",
    "    mg, flow_dict = createOperatorEdge(mg, allNodes[\"operators\"], flow_dict)\n",
    "    for node in allNodes[\"operators\"]:\n",
    "        print('length inNodes:',len(node.inNodes))\n",
    "\n",
    "    # from relationships\n",
    "    mg, flow_dict = createRelationshipEdge(\n",
    "        mg, allNodes[\"relationships\"], nodeById, flow_dict)\n",
    "\n",
    "    # metagraph adjacency matrix and incidence\n",
    "    A = mg.adjacency_matrix()\n",
    "    I = mg.incidence_matrix()\n",
    "\n",
    "    combination_pairs = get_combination_pairs(list(generating_set))\n",
    "\n",
    "    number_of_metapaths = 0\n",
    "    avg_edge_list = 0\n",
    "    avg_include_nodes = 0\n",
    "    metapaths_set = set()\n",
    "    longest_metapath = float('-inf')\n",
    "    shortest_metapath = float('inf')\n",
    "    startNodes = mg.getStartNodes()\n",
    "    endNodes = mg.getEndNodes()\n",
    "    metapaths = mg.get_all_metapaths_from(set(startNodes), set(endNodes))\n",
    "    # if metapaths != None:\n",
    "    #     print(f'Number of metapath from {startNodes} to {endNodes} are {len(metapaths)}')\n",
    "    # for pair in combination_pairs:\n",
    "    #     if set(pair[0]) != set(pair[1]):\n",
    "    #         metapaths = mg.get_all_metapaths_from(set(pair[0]), set(pair[1]))\n",
    "    #         if metapaths != None and len(metapaths) > 0:\n",
    "    #             metapaths_set.update(metapaths)\n",
    "    #             for metapath in metapaths:\n",
    "    #                 number_of_metapaths += 1\n",
    "    #                 longest_metapath = max(longest_metapath, len(metapath.edge_list))\n",
    "    #                 shortest_metapath = min(shortest_metapath, len(metapath.edge_list))\n",
    "    #                 included_nodes = set()\n",
    "    #                 avg_edge_list += len(metapath.edge_list)\n",
    "    #                 for edge in metapath.edge_list:\n",
    "    #                     for tmp_node in edge.invertex.union(edge.outvertex, pair[0], pair[1]):\n",
    "    #                         included_nodes.add(tmp_node)\n",
    "    #                 avg_include_nodes += len(included_nodes)\n",
    "    # number_of_metapaths = len(metapaths_set)\n",
    "    # avg_include_nodes = avg_include_nodes//number_of_metapaths\n",
    "    # avg_edge_list = avg_edge_list//number_of_metapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)\n",
    "\n",
    "plt.xlabel(\"Number of edges\")\n",
    "plt.ylabel(\"Number of metapaths\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa7fd14386e695a05f9216f62e681c51ddd1946c88d0bd0ccabad07041feec0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
